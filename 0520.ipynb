{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98018031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#알렉스넷.\n",
    "#5개의 컨볼루션 레이어와 3개의 풀리 커넥티드 레이어로 구성.\n",
    "#처음으로 맥스풀링을 사용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164961a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 106ms/step - accuracy: 0.3192 - loss: 1.7979 - val_accuracy: 0.4092 - val_loss: 1.7007\n",
      "Epoch 2/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.5070 - loss: 1.3549 - val_accuracy: 0.4562 - val_loss: 1.5619\n",
      "Epoch 3/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 102ms/step - accuracy: 0.5451 - loss: 1.2586 - val_accuracy: 0.4310 - val_loss: 1.6290\n",
      "Epoch 4/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 99ms/step - accuracy: 0.3576 - loss: 3.0559 - val_accuracy: 0.1464 - val_loss: 24.4666\n",
      "Epoch 5/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.1622 - loss: 6.4916 - val_accuracy: 0.1000 - val_loss: 90.7953\n",
      "Epoch 6/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - accuracy: 0.1518 - loss: 56.7786 - val_accuracy: 0.2080 - val_loss: 4.0809\n",
      "Epoch 7/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 156ms/step - accuracy: 0.2152 - loss: 16.5976 - val_accuracy: 0.1917 - val_loss: 34.6221\n",
      "Epoch 8/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 135ms/step - accuracy: 0.2067 - loss: 53.2300 - val_accuracy: 0.2208 - val_loss: 58.8197\n",
      "Epoch 9/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.2225 - loss: 59.1772 - val_accuracy: 0.2513 - val_loss: 35.4158\n",
      "Epoch 10/10\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 123ms/step - accuracy: 0.2359 - loss: 30.6546 - val_accuracy: 0.2404 - val_loss: 63.8386\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.2394 - loss: 62.7856\n",
      "Loss: 63.838600158691406, Accuracy: 24.04000014066696%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Input, Dense, Flatten \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "class AlexNet:\n",
    "    @staticmethod\n",
    "    def build(input_shape=(224,224,3), activation='relu' , class_num=1000):\n",
    "        model = Sequential()\n",
    "        model.add (Input (shape=input_shape))\n",
    "\n",
    "        model.add (Conv2D(96, (11,11), strides=(4,4),\n",
    "            activation=activation, padding=\"same\"))\n",
    "        model.add(MaxPooling2D(pool_size=(3,3), strides=2))\n",
    "        model.add (BatchNormalization())\n",
    "\n",
    "        model.add (Conv2D(256, (5,5), activation=activation, padding=\"same\"))\n",
    "        model.add (MaxPooling2D(pool_size=(3,3), strides=2))\n",
    "        model.add (BatchNormalization())\n",
    "\n",
    "        model.add (Conv2D(384, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(384, (3,3), activation=activation, padding=\"same\")) \n",
    "        model.add (Conv2D(256, (3,3), activation=activation, padding=\"same\"))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add (Dense (4096, activation=activation)) \n",
    "        model.add (Dense(4096, activation=activation))\n",
    "        model.add (Dense(class_num, activation='softmax'))\n",
    "        return model\n",
    "\n",
    "model = AlexNet.build(input_shape = (32,32,3),class_num = 10)\n",
    "\n",
    "model. compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = cifar10. load_data()\n",
    "\n",
    "model.fit(train_X, train_y, validation_data=(test_X, test_y),\n",
    "          batch_size=200, epochs=10, verbose=1)\n",
    "loss, accuracy = model.evaluate(test_X, test_y, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1108a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG19 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afc2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "class VGG19:\n",
    "    @staticmethod\n",
    "    def build(input_shape=(224,224,3), activation='relu'):\n",
    "        model = Sequential()\n",
    "        model.add (Conv2D(64, (3,3), input_shape=input_shape,\n",
    "            activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(64, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add (Conv2D(128, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(128, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add (Conv2D(256, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(256, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(256, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(256, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add (Conv2D(512, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(512, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(512, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(512, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model. add (Conv2D(512, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(512, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(512, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (Conv2D(512, (3,3), activation=activation, padding=\"same\"))\n",
    "        model.add (MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "        model.add (Flatten ())\n",
    "        model.add (Dense(4096, activation=activation))\n",
    "        model.add (Dense(4096, activation=activation))\n",
    "        model.add (Dense(1000, activation='softmax'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d399359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimdaehyeon/Desktop/tensorflow_test/venv_tf/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-05-20 22:23:36.525109: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-05-20 22:23:36.525165: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-05-20 22:23:36.525172: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-05-20 22:23:36.525347: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-05-20 22:23:36.525366: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = VGG19.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23548b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "vgg = VGG19()# model & weights\n",
    "weights = vgg.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c103a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96bd93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before reshape: (224, 224, 3)\n",
      "after reshape: (1, 224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 22:23:42.863685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "[[('n02099712', 'Labrador_retriever', 1.0), ('n02109047', 'Great_Dane', 2.535536e-14), ('n02091831', 'Saluki', 4.8688944e-22)]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img = image.load_img(\"sample.jpg\", target_size=(224,224))\n",
    "img_data = image.img_to_array(img)\n",
    "print(\"before reshape:\", img_data .shape)\n",
    "\n",
    "import numpy as np\n",
    "img_data = img_data[np.newaxis, ...]\n",
    "print(\"after reshape:\", img_data.shape)\n",
    "pred = model.predict(img_data)\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import decode_predictions\n",
    "print(decode_predictions(pred, top=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c9206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
