{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3bd7ea",
   "metadata": {},
   "source": [
    "## Roboflow의 주요 특징    -> 어노테이션 도구로도 사용가능\n",
    "1. 컴퓨터 비전 모델 구축: 이미지 분류, 객체 감지, 세분화 등의 맞춤형 모델을 쉽게 구축할 수 있음.    \n",
    "2. 이미지 주석 달기: 사용자가 데이터를 쉽게 주석을 달고, 데이터셋을 준비할 수 있는 도구 제공.    \n",
    "3. 모델 훈련: 사용자 데이터셋을 기반으로 모델을 훈련시킬 수 있음.  \n",
    "4. 배포 기능: 훈련된 모델을 다양한 환경에 배포할 수 있음.  \n",
    "5. 직관적인 인터페이스: 데이터셋 관리 및 모델 생성을 위한 직관적인 사용자 인터페이스 제공.  \n",
    "6. 자동화된 파이프라인: 모델 훈련, 평가, 배포를 자동화할 수 있는 기능 제공.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f1edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Roboflow\n",
    "from inference_sdk import InferenceHTTPClient\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=\"https://detect.roboflow.com\",\n",
    "    api_key= \"TkYYNlQBnR2sSqe4RBLt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553849d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inference_id': '44d1f36d-2054-4393-98bc-c7fbdf787a0f', 'time': 0.03753161800023008, 'image': {'width': 416, 'height': 416}, 'predictions': [{'x': 191.5, 'y': 357.0, 'width': 41.0, 'height': 48.0, 'confidence': 0.991165816783905, 'class': '2', 'class_id': 2, 'detection_id': 'aeb32ac8-f74b-4c3f-ad82-cd0df154c55a'}, {'x': 77.5, 'y': 142.5, 'width': 35.0, 'height': 45.0, 'confidence': 0.9872434139251709, 'class': '6', 'class_id': 6, 'detection_id': '5c867258-2c89-457e-871d-8a2bd2e752dc'}, {'x': 263.5, 'y': 87.5, 'width': 19.0, 'height': 21.0, 'confidence': 0.9557217955589294, 'class': '6', 'class_id': 6, 'detection_id': '3fd9066d-c1c4-4310-896f-b222e5aa6c13'}, {'x': 71.0, 'y': 328.0, 'width': 46.0, 'height': 84.0, 'confidence': 0.9532557725906372, 'class': '1', 'class_id': 1, 'detection_id': '1b33c5e3-f78d-4c7c-894e-15471ea7754b'}, {'x': 117.0, 'y': 230.5, 'width': 42.0, 'height': 65.0, 'confidence': 0.9077003598213196, 'class': '9', 'class_id': 9, 'detection_id': 'e9d55bd4-ac9e-422d-bcae-fed54f6b65d8'}, {'x': 340.5, 'y': 262.0, 'width': 37.0, 'height': 46.0, 'confidence': 0.8214937448501587, 'class': '0', 'class_id': 0, 'detection_id': 'eabc6be3-2098-4b00-9090-311ff1a7009a'}, {'x': 399.5, 'y': 196.5, 'width': 17.0, 'height': 19.0, 'confidence': 0.7605450749397278, 'class': '9', 'class_id': 9, 'detection_id': 'a0a925a6-1bfd-4f79-9da7-b060fc9bb37a'}, {'x': 278.0, 'y': 215.0, 'width': 20.0, 'height': 24.0, 'confidence': 0.7565137147903442, 'class': '0', 'class_id': 0, 'detection_id': 'b6be42be-ed6e-4110-bbfc-75227c6a2682'}, {'x': 25.5, 'y': 138.5, 'width': 19.0, 'height': 25.0, 'confidence': 0.5891028642654419, 'class': '3', 'class_id': 3, 'detection_id': '7bb0f7cc-5b72-4e8b-a899-de4a073e89d0'}, {'x': 163.5, 'y': 305.5, 'width': 17.0, 'height': 21.0, 'confidence': 0.4858974516391754, 'class': '6', 'class_id': 6, 'detection_id': 'e5638a95-864d-41a8-b624-77486df53704'}, {'x': 25.5, 'y': 138.5, 'width': 19.0, 'height': 25.0, 'confidence': 0.41879233717918396, 'class': '5', 'class_id': 5, 'detection_id': '47577b9e-ec07-424f-b505-75bf96a8beaf'}]}\n"
     ]
    }
   ],
   "source": [
    "file_name = 'data/mnist_image.jpg'\n",
    "result = CLIENT.infer(file_name,model_id=\"numbers-doqnw/3\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f9ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#왼쪽 상단이 기준점 우로 갈수록 x증가, 아래로 갈수록 y증가\n",
    "img = cv2.imread(file_name)\n",
    "for pred in result[\"predictions\"]:\n",
    "    x, y = pred['x'], pred['y']\n",
    "    width, height = pred['width'], pred['height'] #폭과 높이.\n",
    "    conf = pred['confidence']\n",
    "    cls = pred['class']\n",
    "    x1, y1 = int(x-width/2), int(y-height/2)\n",
    "    x2, y2 = int(x+width/2), int(y+height/2)\n",
    "    cv2.rectangle(img, (x1,y1), (x2, y2), (0,0,255), 2) #왼쪽 상단과 오른쪽 하단을 이용해서 사각형을 그림. ,  BGR 중 색 선택, lindwidth\n",
    "    cv2.putText(img, f'{cls} {conf:.4f}', (x1,y1), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255)) #왼쪾 상단에 글씨를 쓰도록 지시.\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4197ffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "#로컬에서 모델 실행하기.\n",
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"TkYYNlQBnR2sSqe4RBLt\")\n",
    "project = rf.workspace().project(\"numbers-doqnw\")\n",
    "model = project.version(3).model\n",
    "\n",
    "filename = 'data/mnist_image.jpg'\n",
    "result = model.predict(filename).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17b1ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416 416 1.5384615384615385 1.5384615384615385\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(filename)\n",
    "img_height, img_width = img.shape[:2]\n",
    "x_ratio, y_ratio = 640/img_width, 640/img_height\n",
    "print(img_width, img_height, x_ratio, y_ratio)\n",
    "for pred in result[\"predictions\"]:\n",
    "    x, y = pred['x'], pred['y']\n",
    "    width, height = pred['width'], pred['height']\n",
    "    conf, cls = pred['confidence'], pred['class']\n",
    "    x1, y1 = int(x-width/2), int(y-height/2)\n",
    "    x2, y2 = int(x+width/2), int(y+height/2)\n",
    "    x1, x2 = int(x1*x_ratio), int(x2*x_ratio)\n",
    "    y1, y2 = int(y1*y_ratio), int(y2*y_ratio)\n",
    "    cv2.rectangle(img, (x1,y1), (x2, y2), (0,0,255), 2)\n",
    "    cv2.putText(img, f'{cls} {conf:.4f}', (x1,y1), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255))\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd5aab",
   "metadata": {},
   "source": [
    "카메라키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6314d169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프레임이 없거나 ESC키가 눌려짐\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, img = cap.read() # True/False, ndarray/None\n",
    "  if (not ret) or (cv2.waitKey(1)==27): # 27키코드는 ESC키\n",
    "    print(\"프레임이 없거나 ESC키가 눌려짐\")\n",
    "    break\n",
    "\n",
    "  # 영상처리 코드 삽입\n",
    "  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  cv2.imshow(\"Camera\", img_gray)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21ef96",
   "metadata": {},
   "source": [
    "## Ultralytics (ultralytics.com)\n",
    "\n",
    "### Ultralytics YOLO의 주요 특징\n",
    "• 사용자 친화적인 인터페이스: 모델을 훈련하고 평가할 수 있도록 다양한 기능을 제공하는 라이브러리를\n",
    "제공. 사용자는 몇 줄의 코드만으로 강력한 객체 탐지 모델을 사용할 수 있음.  \n",
    "• 높은 성능: YOLO 모델은 높은 속도와 정확도를 자랑함. 특히, YOLOv5 및 YOLOv8은 실시간 객체\n",
    "탐지가 가능할 정도로 빠르며, 다양한 환경에서 높은 성능을 발휘함.  \n",
    "• 다양한 모델 버전: 다양한 크기와 성능의 모델을 제공하여 사용자가 자신의 필요에 맞는 모델을 선택할\n",
    "수 있도록 함. 예를 들어, YOLOv8은 nano, small, medium, large 등 여러 버전으로 제공됨.  \n",
    "• 풍부한 기능: 모델 학습을 위한 데이터 증강, 앵커 프리 탐지, 고급 손실 함수 등 다양한 기능이 포함되어\n",
    "있음. 이러한 기능들은 모델의 성능을 향상시키고 다양한 용도에 적합하게 함.  \n",
    "• 커뮤니티 및 지원: 강력한 커뮤니티 지원을 제공하며, 다양한 문서와 튜토리얼을 통해 사용자가 모델을\n",
    "쉽게 이해하고 활용할 수 있도록 도움.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c962ae8",
   "metadata": {},
   "source": [
    "Mosaic Data Augmentation\n",
    " - 데이터 증강의 기법, YOLO4에 소개\n",
    " - 여러장의 미지를 하나의 큰 이미지로 합침,기존 데이터 증강  \n",
    " - 자르기, 크기변환, 반전, 컷-믹스 증강\n",
    " - 이미지의 일부를 다른 이미지의 조각으로 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69045a02",
   "metadata": {},
   "source": [
    "Decoupled Head\n",
    " - 헤드(객체를 찾기위한 출력)가 분리되어 있음.\n",
    " - 출력층 하나가 분류와 회귀를 하는 것이 아니고 분류와 회귀를 위한 층이 2개 존재함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81357714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:04<00:00, 1.42MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                                    name                type  gradient  parameters               shape        mu     sigma\n",
      "    0                     model.0.conv.weight              Conv2d     False         432       [16, 3, 3, 3]  -0.00279     0.152        float32\n",
      "    1                       model.0.bn.weight         BatchNorm2d     False          16                [16]      2.97      1.86        float32\n",
      "    1                         model.0.bn.bias         BatchNorm2d     False          16                [16]     0.249      4.17        float32\n",
      "    2                             model.0.act                SiLU     False           0                  []         -         -              -\n",
      "    3                     model.1.conv.weight              Conv2d     False        4608      [32, 16, 3, 3]  -0.00012     0.063        float32\n",
      "    4                       model.1.bn.weight         BatchNorm2d     False          32                [32]      5.02      1.12        float32\n",
      "    4                         model.1.bn.bias         BatchNorm2d     False          32                [32]     0.942       1.5        float32\n",
      "    5                 model.2.cv1.conv.weight              Conv2d     False        1024      [32, 32, 1, 1]    -0.011    0.0906        float32\n",
      "    6                   model.2.cv1.bn.weight         BatchNorm2d     False          32                [32]      2.22      1.39        float32\n",
      "    6                     model.2.cv1.bn.bias         BatchNorm2d     False          32                [32]     0.802      1.38        float32\n",
      "    7                 model.2.cv2.conv.weight              Conv2d     False        1536      [32, 48, 1, 1]   -0.0045     0.082        float32\n",
      "    8                   model.2.cv2.bn.weight         BatchNorm2d     False          32                [32]      1.21     0.581        float32\n",
      "    8                     model.2.cv2.bn.bias         BatchNorm2d     False          32                [32]     0.544      1.12        float32\n",
      "    9             model.2.m.0.cv1.conv.weight              Conv2d     False        2304      [16, 16, 3, 3]  -0.00119    0.0558        float32\n",
      "   10               model.2.m.0.cv1.bn.weight         BatchNorm2d     False          16                [16]      2.36     0.719        float32\n",
      "   10                 model.2.m.0.cv1.bn.bias         BatchNorm2d     False          16                [16]      1.03       1.7        float32\n",
      "   11             model.2.m.0.cv2.conv.weight              Conv2d     False        2304      [16, 16, 3, 3] -0.000189    0.0477        float32\n",
      "   12               model.2.m.0.cv2.bn.weight         BatchNorm2d     False          16                [16]      2.11     0.513        float32\n",
      "   12                 model.2.m.0.cv2.bn.bias         BatchNorm2d     False          16                [16]     0.919      1.89        float32\n",
      "   13                     model.3.conv.weight              Conv2d     False       18432      [64, 32, 3, 3]  -0.00152    0.0317        float32\n",
      "   14                       model.3.bn.weight         BatchNorm2d     False          64                [64]     0.817     0.207        float32\n",
      "   14                         model.3.bn.bias         BatchNorm2d     False          64                [64]     0.253      0.93        float32\n",
      "   15                 model.4.cv1.conv.weight              Conv2d     False        4096      [64, 64, 1, 1]  -0.00269    0.0534        float32\n",
      "   16                   model.4.cv1.bn.weight         BatchNorm2d     False          64                [64]     0.819     0.361        float32\n",
      "   16                     model.4.cv1.bn.bias         BatchNorm2d     False          64                [64]     0.261      0.78        float32\n",
      "   17                 model.4.cv2.conv.weight              Conv2d     False        8192     [64, 128, 1, 1]  -0.00208    0.0456        float32\n",
      "   18                   model.4.cv2.bn.weight         BatchNorm2d     False          64                [64]     0.712      0.21        float32\n",
      "   18                     model.4.cv2.bn.bias         BatchNorm2d     False          64                [64]   -0.0523     0.753        float32\n",
      "   19             model.4.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00148    0.0341        float32\n",
      "   20               model.4.m.0.cv1.bn.weight         BatchNorm2d     False          32                [32]     0.748     0.155        float32\n",
      "   20                 model.4.m.0.cv1.bn.bias         BatchNorm2d     False          32                [32]    -0.257     0.629        float32\n",
      "   21             model.4.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00153    0.0316        float32\n",
      "   22               model.4.m.0.cv2.bn.weight         BatchNorm2d     False          32                [32]     0.775       0.2        float32\n",
      "   22                 model.4.m.0.cv2.bn.bias         BatchNorm2d     False          32                [32]     0.195     0.696        float32\n",
      "   23             model.4.m.1.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00224     0.031        float32\n",
      "   24               model.4.m.1.cv1.bn.weight         BatchNorm2d     False          32                [32]     0.682     0.106        float32\n",
      "   24                 model.4.m.1.cv1.bn.bias         BatchNorm2d     False          32                [32]    -0.816     0.473        float32\n",
      "   25             model.4.m.1.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00179    0.0276        float32\n",
      "   26               model.4.m.1.cv2.bn.weight         BatchNorm2d     False          32                [32]      1.05     0.241        float32\n",
      "   26                 model.4.m.1.cv2.bn.bias         BatchNorm2d     False          32                [32]     0.527     0.863        float32\n",
      "   27                     model.5.conv.weight              Conv2d     False       73728     [128, 64, 3, 3] -0.000401    0.0189        float32\n",
      "   28                       model.5.bn.weight         BatchNorm2d     False         128               [128]     0.822     0.231        float32\n",
      "   28                         model.5.bn.bias         BatchNorm2d     False         128               [128]    -0.233     0.677        float32\n",
      "   29                 model.6.cv1.conv.weight              Conv2d     False       16384    [128, 128, 1, 1]  -0.00239    0.0326        float32\n",
      "   30                   model.6.cv1.bn.weight         BatchNorm2d     False         128               [128]     0.895       0.4        float32\n",
      "   30                     model.6.cv1.bn.bias         BatchNorm2d     False         128               [128]    -0.135     0.745        float32\n",
      "   31                 model.6.cv2.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00184    0.0283        float32\n",
      "   32                   model.6.cv2.bn.weight         BatchNorm2d     False         128               [128]     0.769     0.206        float32\n",
      "   32                     model.6.cv2.bn.bias         BatchNorm2d     False         128               [128]    -0.588     0.754        float32\n",
      "   33             model.6.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]   -0.0015    0.0203        float32\n",
      "   34               model.6.m.0.cv1.bn.weight         BatchNorm2d     False          64                [64]      1.06     0.177        float32\n",
      "   34                 model.6.m.0.cv1.bn.bias         BatchNorm2d     False          64                [64]    -0.912       0.6        float32\n",
      "   35             model.6.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00149    0.0188        float32\n",
      "   36               model.6.m.0.cv2.bn.weight         BatchNorm2d     False          64                [64]     0.835     0.248        float32\n",
      "   36                 model.6.m.0.cv2.bn.bias         BatchNorm2d     False          64                [64]   -0.0764     0.526        float32\n",
      "   37             model.6.m.1.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00166    0.0192        float32\n",
      "   38               model.6.m.1.cv1.bn.weight         BatchNorm2d     False          64                [64]     0.918     0.175        float32\n",
      "   38                 model.6.m.1.cv1.bn.bias         BatchNorm2d     False          64                [64]     -1.13     0.734        float32\n",
      "   39             model.6.m.1.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000996     0.018        float32\n",
      "   40               model.6.m.1.cv2.bn.weight         BatchNorm2d     False          64                [64]      1.18     0.277        float32\n",
      "   40                 model.6.m.1.cv2.bn.bias         BatchNorm2d     False          64                [64]     0.208     0.765        float32\n",
      "   41                     model.7.conv.weight              Conv2d     False      294912    [256, 128, 3, 3] -0.000505    0.0115        float32\n",
      "   42                       model.7.bn.weight         BatchNorm2d     False         256               [256]     0.961     0.196        float32\n",
      "   42                         model.7.bn.bias         BatchNorm2d     False         256               [256]    -0.718      0.45        float32\n",
      "   43                 model.8.cv1.conv.weight              Conv2d     False       65536    [256, 256, 1, 1]  -0.00268    0.0204        float32\n",
      "   44                   model.8.cv1.bn.weight         BatchNorm2d     False         256               [256]      1.14      0.33        float32\n",
      "   44                     model.8.cv1.bn.bias         BatchNorm2d     False         256               [256]    -0.736     0.573        float32\n",
      "   45                 model.8.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  -0.00162    0.0174        float32\n",
      "   46                   model.8.cv2.bn.weight         BatchNorm2d     False         256               [256]      1.19     0.223        float32\n",
      "   46                     model.8.cv2.bn.bias         BatchNorm2d     False         256               [256]    -0.689     0.484        float32\n",
      "   47             model.8.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000843    0.0128        float32\n",
      "   48               model.8.m.0.cv1.bn.weight         BatchNorm2d     False         128               [128]      1.14     0.205        float32\n",
      "   48                 model.8.m.0.cv1.bn.bias         BatchNorm2d     False         128               [128]    -0.822     0.719        float32\n",
      "   49             model.8.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  -0.00101    0.0124        float32\n",
      "   50               model.8.m.0.cv2.bn.weight         BatchNorm2d     False         128               [128]      1.65     0.368        float32\n",
      "   50                 model.8.m.0.cv2.bn.bias         BatchNorm2d     False         128               [128]    -0.199     0.607        float32\n",
      "   51                 model.9.cv1.conv.weight              Conv2d     False       32768    [128, 256, 1, 1]  -0.00378    0.0238        float32\n",
      "   52                   model.9.cv1.bn.weight         BatchNorm2d     False         128               [128]     0.926     0.248        float32\n",
      "   52                     model.9.cv1.bn.bias         BatchNorm2d     False         128               [128]      1.43     0.657        float32\n",
      "   53                 model.9.cv2.conv.weight              Conv2d     False      131072    [256, 512, 1, 1]   6.2e-05     0.015        float32\n",
      "   54                   model.9.cv2.bn.weight         BatchNorm2d     False         256               [256]     0.942     0.255        float32\n",
      "   54                     model.9.cv2.bn.bias         BatchNorm2d     False         256               [256]     -1.26      0.83        float32\n",
      "   55                               model.9.m           MaxPool2d     False           0                  []         -         -              -\n",
      "   56                                model.10            Upsample     False           0                  []         -         -              -\n",
      "   57                                model.11              Concat     False           0                  []         -         -              -\n",
      "   58                model.12.cv1.conv.weight              Conv2d     False       49152    [128, 384, 1, 1]  -0.00209     0.023        float32\n",
      "   59                  model.12.cv1.bn.weight         BatchNorm2d     False         128               [128]     0.873     0.222        float32\n",
      "   59                    model.12.cv1.bn.bias         BatchNorm2d     False         128               [128]    -0.371     0.819        float32\n",
      "   60                model.12.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  -0.00362    0.0259        float32\n",
      "   61                  model.12.cv2.bn.weight         BatchNorm2d     False         128               [128]     0.739     0.198        float32\n",
      "   61                    model.12.cv2.bn.bias         BatchNorm2d     False         128               [128]    -0.271     0.661        float32\n",
      "   62            model.12.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]  -0.00153    0.0193        float32\n",
      "   63              model.12.m.0.cv1.bn.weight         BatchNorm2d     False          64                [64]     0.833     0.138        float32\n",
      "   63                model.12.m.0.cv1.bn.bias         BatchNorm2d     False          64                [64]    -0.837      0.61        float32\n",
      "   64            model.12.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000776    0.0179        float32\n",
      "   65              model.12.m.0.cv2.bn.weight         BatchNorm2d     False          64                [64]     0.822     0.181        float32\n",
      "   65                model.12.m.0.cv2.bn.bias         BatchNorm2d     False          64                [64]    -0.106     0.635        float32\n",
      "   66                                model.13            Upsample     False           0                  []         -         -              -\n",
      "   67                                model.14              Concat     False           0                  []         -         -              -\n",
      "   68                model.15.cv1.conv.weight              Conv2d     False       12288     [64, 192, 1, 1]  -0.00152    0.0297        float32\n",
      "   69                  model.15.cv1.bn.weight         BatchNorm2d     False          64                [64]     0.541     0.214        float32\n",
      "   69                    model.15.cv1.bn.bias         BatchNorm2d     False          64                [64]     0.166     0.965        float32\n",
      "   70                model.15.cv2.conv.weight              Conv2d     False        6144      [64, 96, 1, 1] -0.000505    0.0346        float32\n",
      "   71                  model.15.cv2.bn.weight         BatchNorm2d     False          64                [64]     0.567     0.264        float32\n",
      "   71                    model.15.cv2.bn.bias         BatchNorm2d     False          64                [64]     0.134     0.946        float32\n",
      "   72            model.15.m.0.cv1.conv.weight              Conv2d     False        9216      [32, 32, 3, 3]  -0.00172    0.0279        float32\n",
      "   73              model.15.m.0.cv1.bn.weight         BatchNorm2d     False          32                [32]     0.663      0.14        float32\n",
      "   73                model.15.m.0.cv1.bn.bias         BatchNorm2d     False          32                [32]    -0.564     0.582        float32\n",
      "   74            model.15.m.0.cv2.conv.weight              Conv2d     False        9216      [32, 32, 3, 3] -0.000878    0.0261        float32\n",
      "   75              model.15.m.0.cv2.bn.weight         BatchNorm2d     False          32                [32]     0.734     0.162        float32\n",
      "   75                model.15.m.0.cv2.bn.bias         BatchNorm2d     False          32                [32]     0.207     0.785        float32\n",
      "   76                    model.16.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000385    0.0134        float32\n",
      "   77                      model.16.bn.weight         BatchNorm2d     False          64                [64]     0.842     0.213        float32\n",
      "   77                        model.16.bn.bias         BatchNorm2d     False          64                [64]    -0.388      0.59        float32\n",
      "   78                                model.17              Concat     False           0                  []         -         -              -\n",
      "   79                model.18.cv1.conv.weight              Conv2d     False       24576    [128, 192, 1, 1]  -0.00125    0.0212        float32\n",
      "   80                  model.18.cv1.bn.weight         BatchNorm2d     False         128               [128]     0.885     0.205        float32\n",
      "   80                    model.18.cv1.bn.bias         BatchNorm2d     False         128               [128]    -0.298     0.609        float32\n",
      "   81                model.18.cv2.conv.weight              Conv2d     False       24576    [128, 192, 1, 1] -0.000884    0.0206        float32\n",
      "   82                  model.18.cv2.bn.weight         BatchNorm2d     False         128               [128]     0.734     0.292        float32\n",
      "   82                    model.18.cv2.bn.bias         BatchNorm2d     False         128               [128]    -0.427     0.761        float32\n",
      "   83            model.18.m.0.cv1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3]   -0.0014    0.0165        float32\n",
      "   84              model.18.m.0.cv1.bn.weight         BatchNorm2d     False          64                [64]       0.8     0.177        float32\n",
      "   84                model.18.m.0.cv1.bn.bias         BatchNorm2d     False          64                [64]    -0.772      0.49        float32\n",
      "   85            model.18.m.0.cv2.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000584    0.0152        float32\n",
      "   86              model.18.m.0.cv2.bn.weight         BatchNorm2d     False          64                [64]      1.19     0.286        float32\n",
      "   86                model.18.m.0.cv2.bn.bias         BatchNorm2d     False          64                [64]   -0.0701     0.665        float32\n",
      "   87                    model.19.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000376   0.00768        float32\n",
      "   88                      model.19.bn.weight         BatchNorm2d     False         128               [128]     0.877      0.21        float32\n",
      "   88                        model.19.bn.bias         BatchNorm2d     False         128               [128]    -0.507     0.364        float32\n",
      "   89                                model.20              Concat     False           0                  []         -         -              -\n",
      "   90                model.21.cv1.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  -0.00112    0.0124        float32\n",
      "   91                  model.21.cv1.bn.weight         BatchNorm2d     False         256               [256]      1.06     0.228        float32\n",
      "   91                    model.21.cv1.bn.bias         BatchNorm2d     False         256               [256]     -0.59     0.577        float32\n",
      "   92                model.21.cv2.conv.weight              Conv2d     False       98304    [256, 384, 1, 1]  -0.00096    0.0109        float32\n",
      "   93                  model.21.cv2.bn.weight         BatchNorm2d     False         256               [256]      1.04     0.317        float32\n",
      "   93                    model.21.cv2.bn.bias         BatchNorm2d     False         256               [256]     -0.89     0.489        float32\n",
      "   94            model.21.m.0.cv1.conv.weight              Conv2d     False      147456    [128, 128, 3, 3] -0.000713   0.00903        float32\n",
      "   95              model.21.m.0.cv1.bn.weight         BatchNorm2d     False         128               [128]      1.03     0.223        float32\n",
      "   95                model.21.m.0.cv1.bn.bias         BatchNorm2d     False         128               [128]     -0.96     0.617        float32\n",
      "   96            model.21.m.0.cv2.conv.weight              Conv2d     False      147456    [128, 128, 3, 3]  -0.00042    0.0083        float32\n",
      "   97              model.21.m.0.cv2.bn.weight         BatchNorm2d     False         128               [128]      1.36     0.252        float32\n",
      "   97                model.21.m.0.cv2.bn.bias         BatchNorm2d     False         128               [128]     -0.55     0.517        float32\n",
      "   98            model.22.cv2.0.0.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000871    0.0138        float32\n",
      "   99              model.22.cv2.0.0.bn.weight         BatchNorm2d     False          64                [64]     0.882     0.357        float32\n",
      "   99                model.22.cv2.0.0.bn.bias         BatchNorm2d     False          64                [64]    -0.501     0.702        float32\n",
      "  100            model.22.cv2.0.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000302    0.0121        float32\n",
      "  101              model.22.cv2.0.1.bn.weight         BatchNorm2d     False          64                [64]      2.41      1.04        float32\n",
      "  101                model.22.cv2.0.1.bn.bias         BatchNorm2d     False          64                [64]     0.923     0.752        float32\n",
      "  102                 model.22.cv2.0.2.weight              Conv2d     False        4096      [64, 64, 1, 1]  5.55e-07    0.0503        float32\n",
      "  102                   model.22.cv2.0.2.bias              Conv2d     False          64                [64]         1      1.39        float32\n",
      "  103            model.22.cv2.1.0.conv.weight              Conv2d     False       73728     [64, 128, 3, 3] -0.000461   0.00909        float32\n",
      "  104              model.22.cv2.1.0.bn.weight         BatchNorm2d     False          64                [64]      1.29     0.492        float32\n",
      "  104                model.22.cv2.1.0.bn.bias         BatchNorm2d     False          64                [64]    -0.394     0.673        float32\n",
      "  105            model.22.cv2.1.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000135    0.0113        float32\n",
      "  106              model.22.cv2.1.1.bn.weight         BatchNorm2d     False          64                [64]      2.56         1        float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  106                model.22.cv2.1.1.bn.bias         BatchNorm2d     False          64                [64]     0.856     0.562        float32\n",
      "  107                 model.22.cv2.1.2.weight              Conv2d     False        4096      [64, 64, 1, 1] -4.08e-07    0.0548        float32\n",
      "  107                   model.22.cv2.1.2.bias              Conv2d     False          64                [64]     0.999      1.31        float32\n",
      "  108            model.22.cv2.2.0.conv.weight              Conv2d     False      147456     [64, 256, 3, 3] -0.000226   0.00654        float32\n",
      "  109              model.22.cv2.2.0.bn.weight         BatchNorm2d     False          64                [64]      1.55     0.415        float32\n",
      "  109                model.22.cv2.2.0.bn.bias         BatchNorm2d     False          64                [64]    -0.257     0.617        float32\n",
      "  110            model.22.cv2.2.1.conv.weight              Conv2d     False       36864      [64, 64, 3, 3] -0.000172    0.0105        float32\n",
      "  111              model.22.cv2.2.1.bn.weight         BatchNorm2d     False          64                [64]      2.95     0.853        float32\n",
      "  111                model.22.cv2.2.1.bn.bias         BatchNorm2d     False          64                [64]     0.826     0.555        float32\n",
      "  112                 model.22.cv2.2.2.weight              Conv2d     False        4096      [64, 64, 1, 1]  5.78e-06    0.0593        float32\n",
      "  112                   model.22.cv2.2.2.bias              Conv2d     False          64                [64]         1      1.32        float32\n",
      "  113            model.22.cv3.0.0.conv.weight              Conv2d     False       46080      [80, 64, 3, 3] -0.000739    0.0119        float32\n",
      "  114              model.22.cv3.0.0.bn.weight         BatchNorm2d     False          80                [80]     0.697     0.247        float32\n",
      "  114                model.22.cv3.0.0.bn.bias         BatchNorm2d     False          80                [80]     -0.58     0.767        float32\n",
      "  115            model.22.cv3.0.1.conv.weight              Conv2d     False       57600      [80, 80, 3, 3] -0.000899      0.01        float32\n",
      "  116              model.22.cv3.0.1.bn.weight         BatchNorm2d     False          80                [80]      2.75     0.655        float32\n",
      "  116                model.22.cv3.0.1.bn.bias         BatchNorm2d     False          80                [80]      1.34      1.83        float32\n",
      "  117                 model.22.cv3.0.2.weight              Conv2d     False        6400      [80, 80, 1, 1]   -0.0123    0.0532        float32\n",
      "  117                   model.22.cv3.0.2.bias              Conv2d     False          80                [80]     -11.4      1.11        float32\n",
      "  118            model.22.cv3.1.0.conv.weight              Conv2d     False       92160     [80, 128, 3, 3] -0.000437   0.00858        float32\n",
      "  119              model.22.cv3.1.0.bn.weight         BatchNorm2d     False          80                [80]     0.872      0.28        float32\n",
      "  119                model.22.cv3.1.0.bn.bias         BatchNorm2d     False          80                [80]    -0.411     0.884        float32\n",
      "  120            model.22.cv3.1.1.conv.weight              Conv2d     False       57600      [80, 80, 3, 3] -0.000971   0.00925        float32\n",
      "  121              model.22.cv3.1.1.bn.weight         BatchNorm2d     False          80                [80]      2.85      1.26        float32\n",
      "  121                model.22.cv3.1.1.bn.bias         BatchNorm2d     False          80                [80]      1.28      1.45        float32\n",
      "  122                 model.22.cv3.1.2.weight              Conv2d     False        6400      [80, 80, 1, 1]   -0.0114    0.0527        float32\n",
      "  122                   model.22.cv3.1.2.bias              Conv2d     False          80                [80]     -10.5     0.911        float32\n",
      "  123            model.22.cv3.2.0.conv.weight              Conv2d     False      184320     [80, 256, 3, 3] -0.000242   0.00608        float32\n",
      "  124              model.22.cv3.2.0.bn.weight         BatchNorm2d     False          80                [80]      1.12     0.328        float32\n",
      "  124                model.22.cv3.2.0.bn.bias         BatchNorm2d     False          80                [80]    -0.289     0.942        float32\n",
      "  125            model.22.cv3.2.1.conv.weight              Conv2d     False       57600      [80, 80, 3, 3]  -0.00099   0.00803        float32\n",
      "  126              model.22.cv3.2.1.bn.weight         BatchNorm2d     False          80                [80]      3.15      1.28        float32\n",
      "  126                model.22.cv3.2.1.bn.bias         BatchNorm2d     False          80                [80]      1.28      1.32        float32\n",
      "  127                 model.22.cv3.2.2.weight              Conv2d     False        6400      [80, 80, 1, 1]   -0.0105    0.0502        float32\n",
      "  127                   model.22.cv3.2.2.bias              Conv2d     False          80                [80]     -9.61     0.937        float32\n",
      "  128                model.22.dfl.conv.weight              Conv2d     False          16       [1, 16, 1, 1]       7.5      4.76        float32\n",
      "YOLOv8n summary: 129 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(129, 3157200, 0, 8.8575488)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "model.info(detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91bdc14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
